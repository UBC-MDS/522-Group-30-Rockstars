---
title: "Strathcona County Housing Price Predictor"
author: "Cal Schafer, Daniel Ortiz, Jordan Lau, William Xu"
bibliography: 
date: "11/28/2020"
output: 
  html_document:
    toc: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
library(knitr)
```

#```{python libraries}
#import pandas as pd
#import altair as alt
#```

# Summary

Here we attempt to build a linear regression model which can use some housing features to predict the assessment value of the residential properties in Strathcona county, AB, Canada. Our final regression model performed well on an unseen test data set, with an overall accuracy calculated to be 0.78. 


# Introduction

The data set used in this project is 2018 Property Tax Assessment from the Open Data portal of Strathcona County, Alberta. It is based on a property valuation date as of July 1, 2017 and property condition date as of December 31, 2017. Each row in the data set represents a property in Strathcona County, and each column represents an attribute of that property (e.g., building size, year built, does it have a fireplace, etc.)
For this project we are trying to answer the question: can we build a prediction model of single-family dwelling property assessment values in Strathcona County based on property features? It is important because it can give those who are interested in buying or selling single family dwellings in that area a sense of the value of houses.
To answer the predictive question, we are planning to build a number of predictive regression model candidates and choose the model with the best accuracy. We plan to partition the data with train test split (90%:10%). Our exploratory data analysis will include creating a heatmap table to summarize the correlation of features and our target, as well as scatterplots for individual features and the target.
Our data pipeline modelling will use a ColumnTransformer to apply different transformations to different feature data types. For example, some of our variables take on values of “Yes/No” and need to be converted to 0’s and 1’s. We also have a categorical feature that will need to be converted to a set of dummy variable features via One-Hot-Encoder. Given that our target (property assessment value) is continuous, there are a couple of modelling approaches. This includes modelling via multi-variable linear regression and modeling via the Ridge method. In Ridge, we will do a hyperparameter optimization to find an alpha that works best for prediction accuracy and control the fundamental tradeoff in our model. Next, we will compare linear regression with Ridge, analyze results, and select a model with better validation accuracy.
When we have the final model chosen, we will fit on the train data set, and evaluate performance with different loss-function metrics such as R2 and MAPE scores, mean squared error (MSE), root mean squared error (RMSE). The values will be saved in a dataframe and presented in our final report.
Our results will be made available in a R Markdown File. Components will include the predicted regression equation and a table of metrics related to the accuracy of our models.


# Methods

## Data

The data set used in this project is 2018 Property Tax Assessment from the Open Data portal of Strathcona County, Alberta. It is based on a property valuation date as of July 1, 2017 and property condition date as of December 31, 2017 (“2018 Property Tax Assessment”) and can be found here. Each row in the data set represents a property in Strathcona County, and each column represents an attribute of that property (e.g., building size, year built, does it have a fireplace, etc.)


## Analysis

The Ridge Regression algorithm was used to predict the housing assessment prices of residential properties in Strathcona County. The features were classified in three types: categorical features that consisted of building description, binary features that consisted of garage, fireplace, basement, basement development, and numerical features that consisted of age, building size, latitude, longitude. All of these features were used to fit the model. The hyperparameter for the ridge model was tuned using cross-validation built into RidgeCV over the range of alpha values 0.0001, 0.001, 0.01, and up to 1000. To assess the model, a 10-fold cross validation using the $R^2$ scoring metric was used on the training dataset. Visible on the feature coefficients table, a 1 feet increase in property size is associated with a $284 assessment value increase assuming other features are held constant. Similarly, having a garage or fireplace is associated with an increase in assessment value of $20637 and $2186 respectively, ceteris paribus. 

The python programming language was used along with the packages numpy (cite), pandas (cite), and scikit-learn(cite). The code used to perform the analysis and create this report can be found *here*

# Results & Discussion
```{r barchart-plot, echo=FALSE, fig.cap="Figure 1. Assessment value frequency distribution", out.height="100%", out.width="100%"}
knitr::include_graphics("../results/barchart.png")
```

#```{python data}
#df = pd.read_csv("../data/2018_Property_Tax_Assessment_clean_train.csv")
#df.info()
#```

```{r train set, echo=FALSE, message=FALSE, warning=FALSE}
train_df <- read_csv("../data/2018_Property_Tax_Assessment_clean_train.csv")
kable(str(train_df), 
      caption="Table 1. Train set structure information")
```


```{r correlation-heat-map, echo=FALSE, fig.cap="Figure 2. Housing features correlation heatmap", out.height="100%", out.width="50%"}
knitr::include_graphics("../results/corrmat.png")
```


```{r scatter-plot, echo=FALSE, fig.cap="Figure 3. Building size vs assessment value scatterplot", out.height="100%", out.width="50%"}
knitr::include_graphics("../results/scatter.png")
```


```{r boxplot, echo=FALSE, fig.cap="Figure 4. Binary housing features vs assessment value boxplots", out.height="100%", out.width="100%"}
knitr::include_graphics("../results/boxplot.png")
```

```{r cross validation scores, echo=FALSE, message=FALSE, warning=FALSE}
cv_score <- read_csv("../results/validation_table.csv")
colnames(cv_score) <- c("Metric", "Dummy regression score", "Ridge regression score")
kable(cv_score, 
      caption="Table 1. Mean cross-validation scores")
```

```{r test scores, echo=FALSE, message=FALSE, warning=FALSE}
test_score <- read_csv("../results/test_score.csv")
colnames(test_score) <- c("Metric", "Ridge regression score")
kable(test_score, 
      caption="Table 2. Test score using Ridge regression")
```
# References